# Chapter 3: Logistic regression



```{r}
date()

```

**_My third week in short_**

- I started the week's work by reading the chapters 5 and 6 of the book *Multivariate Analysis for the Behavioral science* 
- While reading the book I did the Datacamp exercises
- After the above described studying I started to work with the RStudio exercises, that is Data wrangling and analyzing the data
- Analysis and interpretation of the results are reported below

## 3.1 Data

``` {r message = FALSE, warning = FALSE}
# access to all packages needed
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
library(ggpubr)
library(boot)

# read the prepared data set from local file
alc <- read.table("data/alc.csv", sep = ";")

# examine the data
dim(alc)
colnames(alc)

```
In this exercise the data is drawn from the [Student Performance Data set](https://archive.ics.uci.edu/ml/datasets/Student+Performance), which includes information on student achievements in secondary education of two Portuguese schools. After data wrangling, the data set used here consist of 370 observations (rows) of 35 variables (columns), that is information from 370 respondents regarding 35 variables. The names of the variables included in the prepared data set are shown above and more detailed description of them is presented in [the description of the Student Performance Data](https://archive.ics.uci.edu/ml/datasets/Student+Performance). 

### 3.2.1 Selected variables and hypotheses

After examining the variables in the data I chose the following four variables for further examination as I assume they could be associated with the level of alcohol consumption:

1) **_sex_**; student's gender (F = female, M = male) 
2) **_romantic_**; with a romantic relationship (yes or no) 
3) **_studytime_**; weekly study time (numeric: 1 = less than 2 hours, 2 = 2 to 5 hours, 3 = 5 to 10 hours, 4 = over 10 hours) 
4) **_goout_**; going out with friends (from 1 (very low) to 5 (very high))

My hypotheses are:

1) Male students are more likely to be high users of alcohol compared to females
2) Students with a romantic relationship are less likely to be high users compared to those you are not in a relationship
3) Students who spend more time studying are less likely be high users of alcohol than those who study less
4) Students who go out with their friends more often are more likely to be high users of alcohol than the students who go out less often

### 3.2.2 Overview of the selected variables

Below I present the summary tables as well as plots of each variable of interest showing the distributions of the variables in question.

```{r message=FALSE, warning=FALSE}

# before examining the variables I'll transform the two character variables of interest to factors
alc <- mutate(alc, sex = as.factor(sex), romantic = as.factor(romantic))

# pick the names of the variables of interest
varnames <- select(alc, sex, romantic, studytime, goout, high_use) %>%
  colnames()

# summary of each variable
select(alc, varnames) %>%
  summary()

# a bar plot of each variable
gather(alc[varnames]) %>% ggplot(aes(value)) + 
  facet_wrap("key", scales = "free") +
  geom_bar()

```

### 3.2.3 Alcohol consumpion and selected variables 

Next, I examine how the selected variables are related with alcohol consumption. First all variables of interest are tabulated with the 'high use of alcohol' variables, after which the figure shows the proportional distributions of high users.

```{R}

# cross-tabulations with high_use:

# sex and high_use
addmargins(table(alc$sex, alc$high_use))

# romantic and high_use
addmargins(table(alc$romantic, alc$high_use))

# high_use and studytime
addmargins(table(alc$high_use, alc$studytime))

# high_use and goout
addmargins(table(alc$high_use, alc$goout))

# proportion figures

t1 <- ggplot(data = alc, aes(x = sex, fill = high_use)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  ylab("%") +
  xlab("Gender")

t2 <- ggplot(alc, aes(romantic, fill = high_use)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  ylab("%") +
  xlab("Romantic relationship")

t3 <- ggplot(alc, aes(x = goout, fill = high_use)) + 
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  ylab("%") +
  xlab("Go out with friends")

t4 <- ggplot(alc, aes(x = studytime, fill = high_use)) + 
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  ylab("%") +
  xlab("Studytime")

# all plots in one figure
ggarrange(t1 + rremove("legend"), t2 + rremove("legend"), t3 + rremove("legend"), t4 + rremove("legend"),
          ncol = 2, nrow = 2, 
          common.legend = TRUE, legend = "right")


```

The tables and figure above indicate that bigger share of males are high users of alcohol compared to females. Similarly, the more the student go out with friends or the less they use for studying, the bigger is the share of high users. In contrast, the share of high users of alcohol is quite the same among those who are in a romantic relationship and those who are not. Thus, these descriptive results provide support for the above-presented hypotheses 1, 3 and 4, while hypothesis 2 is questionable. 

## 3.3 Logistic regression

```{r}
# logistic regression model
## studytime is used as factors in the model
model1 <- glm(high_use ~ sex + romantic + goout + as.factor(studytime), data = alc, family = "binomial")

# summary of the results
summary(model1)

# compute odds ratios (OR)
OR <- coef(model1) %>% 
  exp

# compute confidence intervals (CI) for the odds ratios
CI <- confint(model1) %>%
    exp

# combine the odds ratios and their confidence intervals
OR_with_CI <- cbind(OR, CI)
# round the results 
round(OR_with_CI, digits = 2)

```

The results from logistic regression model are presented above. Having a romantic relationship is not significantly associated with the use of alcohol The results show that gender, time used for studying and going out with friends are statistically significant explanatory variables of high consumption of alcohol. However, all the associations are not rectilinear, which will be discussed along with odds ratios.

The odds ratios illustrate that males (OR 2.03) are about twice as likely to be high users compared to females. Going out with friends more often increase (OR = 2.10) the likelihood of being high user compared to those who goes out the least often (the actual scale of the variable is somewhat obscure). Finally, compared to students who study less than two hour  those who study 5 to 10 hours are about three times (OR = 0.34) less likely to be high users and respectively those who study over 10 hours (OR = 0.28) are about 3.5 times less likely to be high users. Instead, those who study 2-5 hours are not statistically more or less likely to be high users compared to the reference group. 

### Predictions

According to the above-presented model all variables except 'romance' had statistically significant relationship with high/low alcohol consumption. Next, we build a new regression model without the romance variable and examine how accurate the model predictions are.

```{r}

# new logistic regression model
model2 <- glm(high_use ~ sex + as.factor(studytime) + goout, data = alc, family = "binomial")

# predicted probabilities and prediction (> 0.5) of high_use and add it to the data.frame
probabilities <- predict(model2, type = "response")
alc <- mutate(alc, probability = probabilities)
alc <- mutate(alc, prediction = probability > 0.5)

# tabulate the observed high use versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)

# probability table of high use vs. predictions
prob_table <- table(high_use = alc$high_use, prediction = alc$prediction) %>%
    prop.table %>%
    addmargins
round(prob_table * 100, digits = 2) # probs in % and rounded

ggplot(alc, aes(x = probability, y = high_use, col = prediction)) +
  geom_point(alpha = 0.5, size = 3)

# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# Calculate the share of false predictions (false positives + false negatives)
## this can be seen from the above prob.table as well
loss_func(class = alc$high_use, prob = alc$probability)

```
First table provides shows cross-tabulation of predictions against the actual values of high_use, and the next table shows the proportions of each cell. According to the proportion table about 77.6 % of predictions (cells: False/false + True/true) match with actual values of observations, while 22,4 % of the predictions (cells: True/False + False/True) are false. This is also confimed by using the self-defined 'loss function' to see the share of false predictions, which is 22,4 %.


## 3.4 Cross-validation

### 3.4.1 10-fold cross-validation of the model (bonus)

```{r}

# compute the average number of wrong predictions in the (training) data
## loss func is defined in previous chunk
nwrong_train <- loss_func(class = alc$high_use, prob = alc$probability)
# mean error in in the training data
nwrong_train

# 10-fold cross-validation
crossvalid <- cv.glm(data = alc, cost = loss_func, glmfit = model2, K = 10)
# the mean prediction error for the testing data
crossvalid$delta[1]

```

The mean error in the training data is 0.224. The mean prediction error for the testing data is around 0.24 in the 10-fold cross-validation. The mean prediction error in the Datacamp model was about 0.26, suggesting that the model presented here has slightly better test performance; i.e. the model is more accurate predicting the high consumption of alcohol.

###3.4.2 Finding more parsimonious model (super-bonus)

Here I utilize AIC (*Akaike Information Criteria*) backward elimination -procedure for selecting the explanatory variables for the model. I start by selecting 10 variables and from there start to elimination. 

```{r}

# logistic regression model
model3 <- glm(high_use ~ sex + age + Pstatus + absences + failures + schoolsup + as.factor(studytime) + goout + activities + freetime, data = alc, family = "binomial")

step(model3, direction = "backward")
```
The backward elimination suggest that we should keep five of those original 10 variables; sex, failures, activities, absences and goout. Interestingly, studytime was dropped off! Next, I will run the logistic model with those variables and conduct the 10-fold cross-validation.

```{r}

model4 <- glm(high_use ~ sex + failures + activities + absences + goout,
              data = alc, family = "binomial")

summary(model4)
# 10-fold cross-validation
crossvalid2 <- cv.glm(data = alc, cost = loss_func, glmfit = model4, K = 10)
# the mean prediction error for the testing data
crossvalid2$delta[1]

# visual
probabilities_m4 <- predict(model4, type = "response")
alc <- mutate(alc, probability_m4 = probabilities_m4)
alc <- mutate(alc, prediction_m4 = probability_m4 > 0.5)

ggplot(alc, aes(x = probability_m4, y = high_use, col = prediction_m4)) +
  geom_point(alpha = 0.5, size = 3)


```
The table above present the summary of the fourth model. According to the 10-fold cross-validation, the mean prediction error for the testing data is around 0.20, suggesting that this model has better test performance than the model 3 examined above. The figure provides of graphical confirmation/evidence for this assumption. When I added studytime into the model the prediction error for the testing data increased about one percent, which confirmed that the model actually fits better without it. 