# Chapter 4: Clustering and classification


```{r}
date()

```

**_My fourth week in short_**

- The week started by doing the peer-reviews. It was nice to see what other students have done!
- For warming up I did first the data wrangling exercise (preparing the data for the 5th week exercise)
- Next I started to read the related chapters and figuring out the DataCamp exercises

## 4.1 Data
```{r message=FALSE, warning=FALSE}
# access to packages
library(MASS)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)

# get the data (included in MASS)
data(Boston)

# structure of the data
str(Boston)
dim(Boston)

```

The Boston data set utilized here includes 'Housing Values in Suburbs of Boston', that is different variables relating housing in the city of Boston. The data consists of 506 observations or 14 numeric (or integer) variables (i.e. 506 rows and 14 columns). Description of the variables can be seen from [the description of the data set](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html)

## 4.2 Overview of the Boston data

```{r}
summary(Boston)

# let's use gather from tidyr-package; gather returns key-value pairs of variables
# draw a bar plot of each variable
gather(Boston) %>% 
  ggplot(aes(value)) + 
  facet_wrap("key", scales = "free") +
  geom_histogram()

# construct a correlation matrix and round the results
cor_matrix <-cor(Boston) %>%
    round(digits = 2)

# visualize the correlation matrix
corrplot(cor_matrix, method = "circle", type = "upper", cl.pos = "r", tl.pos = "d", tl.cex = 0.8)

```

*Show a graphical overview of the data and show summaries of the variables in the data Describe and interpret the outputs, commenting on the distributions of the variables and the relationships between them* (CHECK)

Summaries of the variables and the histograms presented above illustrates that the variables in the data set have really skewed distributions. The correlation matrix shows that many of variables are highly correlated. The correlation coefficients vary from 1 to -1. A positive coefficient indicate that high values of variable 'X' are associated with the high values of variable 'Y'. Respectively negative coefficient indicate that high values of 'X' are associated with low values of 'Y'.

## 4.3 Standardized dataset 

First I scale the Boston data, that is standardize the variables and save it as a data.frame instead of a matrix. When variables are centered their mean is adjusted to zero as can be seen from the summaries of the scaled variables which are shown below. Also 

After scaling the data, I will create a new factor variable from the 'crime rate per capita' variable and use the quantiles as cut points. A summary of the new 'crime' variable can be found below.

Finally, I will split the scaled data into a training and testing data sets, which are then used in the next subchapter.

```{r}

# scale the Boston data and transform the matrix to data.frame
boston_scaled <- Boston %>%
  scale() %>%
  as.data.frame()
summary(boston_scaled)

# pick the quantiles of crim
bins <- quantile(boston_scaled$crim)
# create label names
crim_lab <- c("low", "med_low", "med_high", "high")
# create new factor variable
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = crim_lab)
# add the new variable to the data frame and remove the old one
boston_scaled$crime <- crime
boston_scaled <- boston_scaled %>%
  select(-crim)
# summary of the new variable
table(boston_scaled$crime)

'# draw a bar plot of the variable in the new data set
boston_scaled %>%
  select(-crime) %>%
  gather() %>%
  ggplot(aes(value)) + 
  facet_wrap("key", scales = "free") +
  geom_histogram()'

# pick the number of total observations in the data
n <- nrow(boston_scaled)
# take a sample of 80% observations; i.e. pick randomly row numbers between 1 and 0.8 x rows
train_indexes <- sample(n, size = n * 0.8)
# create the training set by using the defined indexes for rows
train_set <- boston_scaled[train_indexes,]
# create the testing set by excluding the row used for training set
test_set <- boston_scaled[-train_indexes,]
```


## 4.4 Linear discriminant analysis 

*Fit the linear discriminant analysis on the train set. Use the categorical crime rate as the target variable and all the other variables in the dataset as predictor variables. Draw the LDA (bi)plot.*

```{r}


```

## Parts 5., 6. and the rest